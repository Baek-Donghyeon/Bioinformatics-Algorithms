{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bioinformatics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1spa6WIJ7AnqFEx23npocnCrRULcEQRwb",
      "authorship_tag": "ABX9TyOEhgXXKyJyyx1rZ+k+cZWm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baek-Donghyeon/Bioinformatics-Algorithms/blob/main/Bioinformatics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0vB1kWjeVkM"
      },
      "source": [
        "# Bioinformatics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKZGqBuzeXD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e8c4aa-687a-410c-99b0-06bece246115"
      },
      "source": [
        "import numpy\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "import itertools\n",
        "from functools import reduce\n",
        "import copy\n",
        "import heapq\n",
        "import math\n",
        "sys.setrecursionlimit(3000)\n",
        "\n",
        "\n",
        "gen_code = {'AAA':'K','AAC':'N','AAG':'K','AAU':'N','ACA':'T','ACC':'T','ACG':'T','ACU':'T',\n",
        "            'AGA':'R','AGC':'S','AGG':'R','AGU':'S','AUA':'I','AUC':'I','AUG':'M','AUU':'I',\n",
        "            'CAA':'Q','CAC':'H','CAG':'Q','CAU':'H','CCA':'P','CCC':'P','CCG':'P','CCU':'P',\n",
        "            'CGA':'R','CGC':'R','CGG':'R','CGU':'R','CUA':'L','CUC':'L','CUG':'L','CUU':'L',\n",
        "            'GAA':'E','GAC':'D','GAG':'E','GAU':'D','GCA':'A','GCC':'A','GCG':'A','GCU':'A',\n",
        "            'GGA':'G','GGC':'G','GGG':'G','GGU':'G','GUA':'V','GUC':'V','GUG':'V','GUU':'V',\n",
        "            'UAA':'*','UAC':'Y','UAG':'*','UAU':'Y','UCA':'S','UCC':'S','UCG':'S','UCU':'S',\n",
        "            'UGA':'*','UGC':'C','UGG':'W','UGU':'C','UUA':'L','UUC':'F','UUG':'L','UUU':'F'}\n",
        "\n",
        "int_mass = {'G':57,'A':71,'S':87,'P':97,'V':99,'T':101,'C':103,'I':113,'L':113,'N':114,\n",
        "            'D':115,'K':128,'Q':128,'E':129,'M':131,'H':137,'F':147,'R':156,'Y':163,'W':186}\n",
        "\n",
        "red_mass = {'G':57,'A':71,'S':87,'P':97,'V':99,'T':101,'C':103,'I':113,'N':114,\n",
        "            'D':115,'K':128,'E':129,'M':131,'H':137,'F':147,'R':156,'Y':163,'W':186}\n",
        "\n",
        "\n",
        "def k_mer_of(text, k):\n",
        "\n",
        "  for i in range(len(text) - k + 1):\n",
        "    yield text[i:i+k]\n",
        "\n",
        "\n",
        "def ham(pat, text):\n",
        "\n",
        "  k = len(pat)\n",
        "  dis = k\n",
        "\n",
        "  for k_mer in k_mer_of(text, k):\n",
        "    dis = min(dis, sum(pat[j] != k_mer[j] for j in range(k)))\n",
        "  \n",
        "  return dis\n",
        "\n",
        "\n",
        "def pat_to_num(pat):\n",
        "\n",
        "  sym_to_num = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "\n",
        "  if len(pat) == 0:\n",
        "      return 0\n",
        "  return 4*pat_to_num(pat[:-1]) + sym_to_num[pat[-1]]\n",
        "\n",
        "\n",
        "def num_to_pat(num, k):\n",
        "\n",
        "  num_to_sym = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n",
        "\n",
        "  try:\n",
        "    if k == 1:\n",
        "      return num_to_sym(num)\n",
        "    return num_to_pat(num // 4, k-1) + num_to_sym[num % 4]\n",
        "  except:\n",
        "    raise ValueError()\n",
        "\n",
        "\n",
        "def count_pat(text, pat):\n",
        "\n",
        "  return sum(k_mer == pat for k_mer in k_mer_of(text, len(pat)))\n",
        "\n",
        "\n",
        "def find_freq_k_mer(text, k, dis = 0, re = False):\n",
        "\n",
        "  freq_dict = dict(freq_dict(text, k, dis, re))\n",
        "  max = max(freq_dict, key = lambda x : freq_dict[x])\n",
        "\n",
        "  return list(filter(lambda x : x[1] == max, freq_dict.items())) \n",
        "\n",
        "\n",
        "def freq_dict(text, k, dis = 0, re = False):\n",
        "  \n",
        "  if re:\n",
        "    return freq_dict(re_complement(text), k, dis) + freq_dict(text, k, dis)\n",
        "  else:\n",
        "    return Counter([neigh for k_mer in k_mer_of(text, k) for neigh in neigh(k_mer, dis)])\n",
        "\n",
        "\n",
        "def re_complement(text):\n",
        "\n",
        "  compliment_dict = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G'}\n",
        "  return ''.join(reversed([compliment_dict[base] for base in text]))\n",
        "\n",
        "\n",
        "def find_pat_occur(text, pat, dis = 0):\n",
        "\n",
        "  # ham(text, pat) â‰¤ d\n",
        "  k = len(pat)\n",
        "  return [i for i in range(len(text) - k + 1) if ham(text[i:i+k], pat) <= dis]\n",
        "\n",
        "\n",
        "def find_clump(text, k, L, t):\n",
        "\n",
        "  '''\n",
        "  k   length of the k_mer\n",
        "  L   length of an interval\n",
        "  t   min ocurrences of a pat in the interval\n",
        "  '''\n",
        "\n",
        "  pos_dict = defaultdict(list)\n",
        "  freq_dict = freq_dict(text, k)\n",
        "  for pat, freq in freq_dict.items():\n",
        "    if freq >= t:\n",
        "      pos_dict[pat] = find_occurrences_of_pat(text, pat)\n",
        "  for pat, pos in pos_dict.items():\n",
        "    for i in range(len(pos) - t + 1):\n",
        "      if pos[i+t-1] - pos[i] <= L - k + 1:\n",
        "        yield pat\n",
        "\n",
        "\n",
        "def find_min_skew_pos(text):\n",
        "\n",
        "  # skew : abs(#'G'-#'C')\n",
        "  skew = [0]\n",
        "  for base in text:\n",
        "    if base == 'C': skew.append(skew[-1]-1)\n",
        "    elif base == 'G': skew.append(skew[-1]+1)\n",
        "    else: skew.append(skew[-1])\n",
        "  min = min(skew)\n",
        "  return list(filter(lambda x : x == min, skew)) # return minimum skew\n",
        "\n",
        "\n",
        "def neigh(pat, dis):\n",
        "\n",
        "  length = len(pat)\n",
        "  mis_base = itertools.product(\"ACTG\", repeat = dis) # all possible 'dis' length letter strings\n",
        "  for poss in itertools.combinations(iter(range(length)), dis):\n",
        "    for base in mis_base:\n",
        "      neigh = copy.deepcopy(pat)\n",
        "      for i in dis:\n",
        "        neigh[pos[i]] = base[i]\n",
        "        yield neigh\n",
        "      \n",
        "\n",
        "def enum_motif(strings, k, dis):\n",
        "\n",
        "  # find all (k, dis)-motifs in a collect of strings.\n",
        "  neigh_list = []\n",
        "  for text in strings:\n",
        "    neigh_list.append(set(neigh(text, k, dis)))\n",
        "  motifs = neigh_list[0]\n",
        "  for neigh in neigh_list:\n",
        "    motifs = motifs & neigh\n",
        "  return list(motifs)\n",
        "\n",
        "\n",
        "def find_median_string(strings, k, dis = 0):\n",
        "\n",
        "  # a median string for Dna minimizes d(pat, Dna) over all k-mers pat.\n",
        "  motifs = enum_motif(strings, k, dis)\n",
        "  if not motifs:\n",
        "    find_median_string(strings, k, dis + 1)\n",
        "  else:\n",
        "    motifs_dict = defaultdict(int)\n",
        "    for pat in motifs:\n",
        "      motifs_dict[pat] = sum(ham(pat, text) for text in strings)\n",
        "    return min(motifs_dict, key = lambda x : motifs_dict[x]) # return key that minimizes the value\n",
        "\n",
        "\n",
        "def find_prob_k_mer(text, k, profile):\n",
        "\n",
        "  # A k-mer that was most likely to have been generated by Profile among all k-mers in Text.\n",
        "  best_score = 0\n",
        "  for k_mer in k_mer_of(text, k):\n",
        "    s = dna_score(profile, [k_mer])\n",
        "    if best_score < s:\n",
        "      best_score = s\n",
        "      prob_k_mer = k_mer\n",
        "  return prob_k_mer\n",
        "\n",
        "\n",
        "def dna_score(profile, motif):\n",
        "\n",
        "  str_len = len(motif[0])\n",
        "  return sum(reduce(lambda x, y: x*y, [profile[pat_to_num(k_mer[i])][i]\n",
        "              for i in range(str_len)]) for k_mer in motif)\n",
        "\n",
        "\n",
        "def form_profile(motif):\n",
        "\n",
        "  k = len(motif[0])\n",
        "  profile = numpy.full((4,k), 1) # pseudocount\n",
        "  for i in range(k):\n",
        "    for k_mer in motif:\n",
        "      profile[pat_to_num(k_mer[i])][i] += 1\n",
        "  return profile/(len(motif)+4)\n",
        "\n",
        "\n",
        "def greedy_motif_search(strings, k):\n",
        "\n",
        "  best_motif = [text[:k] for text in strings]\n",
        "  for k_mer in k_mer_of(strings[0], k):\n",
        "    motif = [k_mer]\n",
        "    for j in range(1,len(strings)):\n",
        "      profile = form_profile(motif)\n",
        "      motif.append(find_prob_k_mer(strings[j], k, profile))\n",
        "    if dna_score(form_profile(best_motif), best_motif) < dna_score(form_profile(motif), motif):\n",
        "      best_motif = motif\n",
        "  return best_motif\n",
        "\n",
        "\n",
        "def gibbs_sampler(strings, k, n):\n",
        "  str_len = len(strings[0])\n",
        "  t = len(strings)\n",
        "  best_motif_score = 0\n",
        "\n",
        "  for time in range(n):\n",
        "\n",
        "    # generate random motif\n",
        "    motif = []\n",
        "    for i in range(t):\n",
        "      motif.append(random.choice([k_mer for k_mer in k_mer_of(strings[i], k)]))\n",
        "\n",
        "    # update the motif the profile matches best\n",
        "    last = None\n",
        "    while motif != last:\n",
        "      last = motif\n",
        "      for i in range(t):\n",
        "        motif[i] = find_prob_k_mer(strings[i], k, form_profile([motif[j] for j in range(t) if j != i]))\n",
        "    \n",
        "    motif_score = dna_score(form_profile(motif), motif)\n",
        "\n",
        "    if best_motif_score < motif_score:\n",
        "      best_motif_score = motif_score\n",
        "      best_motif = motif\n",
        "      print(best_motif_score)\n",
        "\n",
        "  return best_motif\n",
        "\n",
        "\n",
        "def rand_motif_search(strings, k):\n",
        "\n",
        "  str_len = len(strings[0])\n",
        "  t = len(strings)\n",
        "  best_motif_score = 0 # score\n",
        "  \n",
        "  for time in xrange(800):\n",
        "\n",
        "    # generate random motif\n",
        "    motif = []\n",
        "    for i in range(t):\n",
        "      motif.append(random.choice([k_mer for k_mer in k_mer_of(strings[i], k)]))\n",
        "    better_motif = motif\n",
        "\n",
        "    # converge to a local optimum\n",
        "    while True:\n",
        "      profile = form_profile(better_motif)\n",
        "      motif = []\n",
        "      for j in range(t):\n",
        "        motif.append(find_prob_k_mer(strings[j], k, profile))\n",
        "        motif_score = dna_score(profile, better_motif)\n",
        "      if motif_score < dna_score(form_profile(motif), motif):\n",
        "        better_motif = motif\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    if best_motif_score < motif_score:\n",
        "      best_motif_score = motif_score\n",
        "      best_motif = better_motif\n",
        "\n",
        "  return best_motif\n",
        "\n",
        "\n",
        "def find_string(strings, d = None):\n",
        "\n",
        "  first = strings[0]\n",
        "\n",
        "  if d != None: # paired\n",
        "    half = len(first)//2\n",
        "    return find_string([front[:half] for front in strings]) + find_string([rear[half:] for rear in strings[-half-d:]])\n",
        "\n",
        "  return first[:-1] + ''.join([text[-1] for text in strings]) \n",
        "\n",
        "def de_brujin_graph(strings):\n",
        "\n",
        "  graph = defaultdict(list)\n",
        "\n",
        "  if len(strings[0]) == 2: # paired\n",
        "    for f,r in strings: # ex) GAGA|TTGA, f = GAGA, r = TTGA\n",
        "      graph[f[:-1]+r[:-1]].append(f[1:]+r[1:])         \n",
        "  else: # unpaired\n",
        "    for k_mer in strings:\n",
        "      graph[k_mer[:-1]].append(k_mer[1:])\n",
        "  return graph\n",
        "\n",
        "\n",
        "def eulerian(graph):\n",
        "\n",
        "  # determine whether it is an eulerian path or cycle\n",
        "  graph = copy.deepcopy(graph)\n",
        "  in_degree = Counter(list(itertools.chain(*graph.values())))\n",
        "  out_degree = Counter([k for k,v in graph.items() for __ in range(len(v))])\n",
        "  odd_degree = (out_degree - in_degree).keys()\n",
        "  if odd_degree:\n",
        "    stack = list(odd_degree) # start from odd_degree / eulerian path\n",
        "  else:\n",
        "    stack = [list(graph.keys())[0]] # start from arbitrary node / eulerian cycle\n",
        "\n",
        "  # DFS\n",
        "  visit = []\n",
        "  while stack:\n",
        "    try:\n",
        "      stack.append(graph[stack[-1]].pop())\n",
        "    except: # backtrack\n",
        "      visit.append(stack.pop())\n",
        "  visit.reverse()\n",
        "  return visit\n",
        "\n",
        "\n",
        "def reconstruct_string(strings, d = None):\n",
        "\n",
        "  # d = # of bases b/w front and rear ends\n",
        "  return find_string(eulerian(de_brujin_graph(strings)),d)\n",
        "\n",
        "\n",
        "def find_k_universal_circular_string(k):\n",
        "\n",
        "  # [:-k+1] : for circular_string\n",
        "  return reconstruct_string(list(map(''.join, product('01', repeat=k))))[:-k+1]\n",
        "\n",
        "\n",
        "def generate_contig(strings):\n",
        "\n",
        "  graph = de_brujin_graph(strings)\n",
        "\n",
        "  # branch : in != 1 & out != 1\n",
        "  in_degree = Counter(list(itertools.chain(*graph.values())))\n",
        "  out_degree = Counter([k for k,v in graph.items() for __ in range(len(v))])\n",
        "  branch = set(node for node in in_degree.keys() if in_degree[node] != 1)\n",
        "  branch = branch & set(node for values in graph.values() for node in values if out_degree[node] != 1)\n",
        "  \n",
        "  # append node until branch\n",
        "  collect = []\n",
        "  for node in branch:\n",
        "    while graph[node]:\n",
        "      contig = [node, graph[node].pop()]\n",
        "      while contig[-1] not in branch:\n",
        "        contig.append(graph[contig[-1]].pop())\n",
        "      collect.append(find_string(contig))\n",
        "  return collect\n",
        "\n",
        "\n",
        "def translate(text):\n",
        "\n",
        "  aa = []\n",
        "  for i in range(0,len(text),3):\n",
        "    codon = text[i:i+3]\n",
        "    if codon in ['UAA','UAG','UGA']:\n",
        "      break\n",
        "    aa.append(gen_code[codon])\n",
        "  return ''.join(aa)\n",
        "\n",
        "\n",
        "def dna_to_rna(text):\n",
        "  return re.sub('T','U',text)\n",
        "\n",
        "\n",
        "def find_encoding_string(text, pep):\n",
        "  pep_len = len(pep)\n",
        "  answer = []\n",
        "  for i in range(len(text)-3*pep_len+1):\n",
        "    string = text[i:i+3*pep_len]\n",
        "    if translate(dna_to_rna(string)) == pep or translate(dna_to_rna(re_complement(string))) == pep:\n",
        "      answer.append(string)\n",
        "  return answer\n",
        "\n",
        "\n",
        "def spectrum(pep, cyclo = False):\n",
        "\n",
        "  pep_len = len(pep)\n",
        "  spec = [0]\n",
        "\n",
        "  if cyclo:\n",
        "    spec.append(sum(pep))\n",
        "    circle = pep+pep\n",
        "    for i in range(pep_len):\n",
        "      for j in range(1, pep_len):\n",
        "        spec.append(sum(circle[i:i+j]))\n",
        "    return sorted(spec)\n",
        "  else: # linear\n",
        "    for i in range(pep_len):\n",
        "      for j in range(i, pep_len):\n",
        "        spec.append(sum(pep[i:j+1]))\n",
        "    return sorted(spec)\n",
        "\n",
        "def aa_to_mass(pep):\n",
        "  return [int_mass[aa] for aa in pep]\n",
        "\n",
        "def mass(pep):\n",
        "  return sum([int_mass[aa] for aa in pep])\n",
        "\n",
        "\n",
        "def num_of_pep(m):\n",
        "  d = defaultdict(int)\n",
        "  aa_mass = red_mass.values()\n",
        "  d[0] = 1 # single amino acid\n",
        "  for i in range(1,m+1):\n",
        "    d[i] = sum([d[i-j] for j in aa_mass if i-j >= 0])\n",
        "  return d[m]\n",
        "\n",
        "\n",
        "def pep_score(pep, spec, cyclo = False):\n",
        "  score = 0\n",
        "  s = spectrum(pep, cyclo)\n",
        "  # the scoring function takes into account the multiplicity\n",
        "  for frag in spec:\n",
        "    if frag in s:\n",
        "      s.remove(frag)\n",
        "      score += 1\n",
        "  return score\n",
        "\n",
        "\n",
        "def leaderboard_cyclo_seq(spec, n, m):\n",
        "\n",
        "  candidate = convolution(spec, n)\n",
        "  leader_board = candidate\n",
        "  leader_pep = []\n",
        "  total_mass = max(spec)\n",
        "\n",
        "  def trim(leader_board, spec, n):\n",
        "    # return the top m hiehgest-scoring peptides with ties\n",
        "    l = []\n",
        "    for pep in leader_board:\n",
        "      l.append([pep_score(pep, spec),pep])\n",
        "\n",
        "    l = sorted(l, key = lambda x : x[0], reverse=True)\n",
        "    for i in range(n+1, len(l)): # top m elements\n",
        "      if l[n][0] > l[i][0]:\n",
        "        leader_board = [v for k,v in l[:i-1]]\n",
        "        break\n",
        "\n",
        "    return leader_board\n",
        "\n",
        "  while True:\n",
        "    l_b = copy.deepcopy(leader_board)\n",
        "    for pep in l_b:\n",
        "      sub_mass = sum(pep)\n",
        "      if sub_mass == total_mass:\n",
        "        if pep_score(pep, spec, cyclo=True) > pep_score(leader_pep, spec, cyclo=True):\n",
        "          leader_pep = pep\n",
        "      elif sub_mass > total_mass:\n",
        "        leader_board.remove(pep)\n",
        "\n",
        "    # break if leader_board is empty\n",
        "    if not leader_board:\n",
        "      break\n",
        "    \n",
        "    leader_board = trim(leader_board, spec, m)\n",
        "    # add an a.a. to pep\n",
        "    leader_board = [pep+aa for pep in leader_board for aa in candidate]\n",
        "\n",
        "  return leader_pep\n",
        "\n",
        "\n",
        "def convolution(spec, n):\n",
        "\n",
        "  convol = defaultdict(int)\n",
        "  answer = []\n",
        "\n",
        "  # add differences of masses to convol\n",
        "  for i in spec:\n",
        "    for j in spec:\n",
        "      if i-j > 0:\n",
        "        convol[i-j] += 1\n",
        "  \n",
        "  l = sorted(convol.items(), key = lambda x : x[1], reverse=True)\n",
        "  for i in range(n+1, len(l)): # top m elements\n",
        "    if l[n][1] > l[i][1]:\n",
        "      return [[k] for k,v in l[:i-1] if k in red_mass.values()]\n",
        "      break\n",
        "\n",
        "  return [[k] for k,v in l if k in red_mass.values()]\n",
        "\n",
        "\n",
        "def turn_pike(L, A=[0]):\n",
        "\n",
        "  L = copy.deepcopy(L)\n",
        "  \n",
        "  # remove pairwise differencese b/w points in A[:-1] and A[-1]\n",
        "  for a in A[:-1]:\n",
        "    L.remove(a - A[-1])\n",
        "    L.remove(A[-1] - a)\n",
        "  L.remove(0)\n",
        "\n",
        "  if not L:\n",
        "    return sorted(A)\n",
        "  else:\n",
        "    try:\n",
        "      return turn_pike(L, A+[max(L)])\n",
        "    except:\n",
        "      return turn_pike(L, A+[max(A)-max(L)])\n",
        "\n",
        "\n",
        "f = open('/content/drive/My Drive/Colab Notebooks/input.txt', 'r')\n",
        "L = f.readline()\n",
        "L = list(map(int,L.split()))\n",
        "print(' '.join(list(map(str,turn_pike(L)))))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 16 26 28 30 40 58 69 72 83 98 102 114 115 124 131 146 148 152 153 163 165 168 176 181 193 201 205 208 226 241 252 269 281 299 306 323 338 351 369 385 391 397 408 424 433 445 459 477 482 483 492 496 502 515 527 537 541 545 546 560 565 576 580 588 591 602 611 622 625 642 650 656 674 688 700 716 729 744 758 767 781 788 802 808 811 818 830 842 850 854 867 882 885 892 898 916 923 934 948 961 973 985 994 1009 1019 1023 1035 1050 1060 1063 1078 1093 1110 1119 1138 1146 1151 1156 1169 1171 1175 1178 1190 1207 1214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IOLJRo7kpL3",
        "outputId": "47ecdde4-ec4e-48cd-a53e-eb6f3685027d"
      },
      "source": [
        "a = [0] * 2\r\n",
        "a[1] += 1\r\n",
        "print(a)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPTIdW_DcOQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41550c5d-3be2-447f-e7df-e52879ab9e23"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}