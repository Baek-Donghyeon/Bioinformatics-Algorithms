{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bioinformatics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1spa6WIJ7AnqFEx23npocnCrRULcEQRwb",
      "authorship_tag": "ABX9TyNdR+Lfw//Ksi490+4GO+Cf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baek-Donghyeon/Bioinformatics-Algorithms/blob/main/Bioinformatics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0vB1kWjeVkM"
      },
      "source": [
        "# Bioinformatics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKZGqBuzeXD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b346503-7c45-45bd-9f7f-cbf48bbf4282"
      },
      "source": [
        "import numpy\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "from collections import defaultdict\n",
        "from itertools import combinations\n",
        "sys.setrecursionlimit(3000)\n",
        "\n",
        "def hamming_distance(p, q):\n",
        "  if len(p) != len(q):\n",
        "    raise ValueError('len(p) != len(q)')\n",
        "  distance = 0\n",
        "  for i in range(len(p)):\n",
        "    if p[i] != q[i]:\n",
        "      distance += 1\n",
        "  return distance\n",
        "\n",
        "def pattern_to_number(pattern):\n",
        "  symbol_to_number = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "  if len(Pattern) == 0:\n",
        "      return 0\n",
        "  return 4*pattern_to_number(pattern[:-1]) + symbol_to_number[pattern[-1]]\n",
        "\n",
        "def number_to_pattern(number, k):\n",
        "  number_to_symbol = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n",
        "  if k == 1:\n",
        "    return number_to_symbol(number)\n",
        "  return number_to_pattern(number // 4, k-1) + number_to_symbol[number % 4]\n",
        "\n",
        "def count_pattern(text, pattern):\n",
        "  count = 0\n",
        "  k = len(pattern)\n",
        "  for i in range(len(Text)-k+1):\n",
        "      if text[i:i+k] == pattern:\n",
        "          count += 1\n",
        "  return count\n",
        "\n",
        "def find_frequent_k_mers(text, k, distance = 0, reverse_complement = False):\n",
        "  ''' k   length of the k_mer '''\n",
        "  answer = []\n",
        "  k_mers = frequency_dict(text, k, d, reverse_complement)\n",
        "  max_frequency = max(k_mers.values())\n",
        "  for pattern, frequency in k_mers.items():\n",
        "    if frequency == max_frequency:\n",
        "      answer.append(pattern)\n",
        "  return answer\n",
        "\n",
        "def frequency_dict(text, k, distance = 0, reverse_complement = False):\n",
        "  ''' k   length of the k_mer '''\n",
        "  k_mers = defaultdict(int)\n",
        "  for i in range(len(text) - k + 1):\n",
        "    for neighbor in neighbors(text[i:i+k], distance):\n",
        "      k_mers[neighbor] += 1\n",
        "  if reverse_complement:\n",
        "    text = reverse_complement(text)\n",
        "    for i in range(len(text) - k + 1):\n",
        "      for neighbor in neighbors(text[i:i+k], distance):\n",
        "        k_mers[neighbor] += 1\n",
        "  return k_mers\n",
        "\n",
        "def reverse_complement(text):\n",
        "  compliment_dict = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G'}\n",
        "  answer = []\n",
        "  for i in text:\n",
        "    answer += compliment_dict[i]\n",
        "  return answer[::-1] # reverse the sequence\n",
        "\n",
        "def find_pattern_occurences(text, pattern, distance = 0):\n",
        "  # hamming_distance(text, pattern) â‰¤ d\n",
        "  positions = []\n",
        "  k = len(pattern)\n",
        "  for i in range(len(text) - k + 1):\n",
        "    if hamming_distance(text[i:i+k], pattern) <= distance:\n",
        "      positions.append(i)\n",
        "  return positions\n",
        "\n",
        "def find_clump(text, k, L, t):\n",
        "  '''\n",
        "  k   length of the k_mer\n",
        "  L   length of an interval\n",
        "  t   min ocurrences of a pattern in the interval\n",
        "  '''\n",
        "  answer = []\n",
        "  position_dict = defaultdict(list)\n",
        "  frequency_dict = frequency_dict(text, k)\n",
        "  for pattern, frequency in frequency_dict.items():\n",
        "    if frequency >= t:\n",
        "      position_dict[pattern] = find_occurrences_of_pattern(text, pattern)\n",
        "  for pattern, position in position_dict.items():\n",
        "    if max(Position) - min(Position) < L:\n",
        "      answer.append(pattern)\n",
        "  return answer\n",
        "\n",
        "def find_min_skew_position(text):\n",
        "  # skew : abs(#'G'-#'C')\n",
        "  answer = []\n",
        "  skew = [0]\n",
        "  for base in text:\n",
        "    if base == 'C':\n",
        "      skew.append(skew[-1]-1)\n",
        "    elif base == \"G':\n",
        "      skew.append(skew[-1]+1)\n",
        "    else:\n",
        "      skew.append(skew[-1])\n",
        "  min = min(skew)\n",
        "  for i in range(len(skew)):\n",
        "    if skew[i] == min:\n",
        "      answer.append(i)\n",
        "  return answer\n",
        "\n",
        "def neighbors(text, distance):\n",
        "  answer = []\n",
        "  length = len(text)\n",
        "  mismatch_positions = list(combinations(length, distance))\n",
        "  mismatch_base = [number_to_pattern(number) for number in range(4**k)]\n",
        "  for positions in mismatch_positions:\n",
        "    for base in mismatch_base:\n",
        "      neighbor = text\n",
        "      for i in distance:\n",
        "        neighbor(positions[i]) = base[i]\n",
        "      answer.append(neighbor)\n",
        "  return answer\n",
        "      \n",
        "\n",
        "def enumerate_motif(texts, k, distance):\n",
        "# Find all (k, distance)-motifs in a collection of strings.\n",
        "  neighbors_list = []\n",
        "  for text in texts:\n",
        "    neighbors_list.append(set(neighbors(text, k, distance)))\n",
        "  motifs = neighbors_list[0]\n",
        "  for neighbors in neighbors_list:\n",
        "    motifs = motifs & neighbors\n",
        "  return list(motifs)\n",
        "\n",
        "def DistanceBetweenPatternAndStrings(Pattern, Dna):\n",
        "#Find the distance between a pattern and a set of strings.\n",
        "  k = len(Pattern)\n",
        "  distance = 0\n",
        "  for string in Dna:\n",
        "    HamDistance = k\n",
        "    for i in range(len(string)-k+1):\n",
        "      CurrentDistance = HammingDistance(Pattern, string[i:i+k])\n",
        "      if HamDistance > CurrentDistance:\n",
        "        HamDistance = CurrentDistance\n",
        "    distance += HamDistance\n",
        "  return distance\n",
        "\n",
        "\n",
        "def MedianString(Dna, k):\n",
        "#Find a median string.\n",
        "#A median string for Dna minimizes d(Pattern, Dna) over all k-mers Pattern.\n",
        "  distance = len(Dna)*k\n",
        "  Median = ''\n",
        "  for i in range(4**k):\n",
        "    Pattern = NumberToPattern(i, k)\n",
        "    CurrentDistance = DistanceBetweenPatternAndStrings(Pattern, Dna)\n",
        "    if distance > CurrentDistance:\n",
        "      distance = CurrentDistance\n",
        "      Median = Pattern\n",
        "  return Median\n",
        "\n",
        "\n",
        "def ProfileMostProbableKmer(Text, k, Profile):\n",
        "#Find a Profile-most probable k-mer in a string.\n",
        "#Profile-most probable k-mer in Text, a k-mer that was most likely to have been generated by Profile among all k-mers in Text.\n",
        "  Score = 0\n",
        "  Kmer = ''\n",
        "  for i in range(len(Text)-k):\n",
        "    CurrentScore = 1\n",
        "    kmer = Text[i:i+k]\n",
        "    for j in range(k):\n",
        "      CurrentScore *= Profile[kmer[j]][j]\n",
        "    if CurrentScore > Score:\n",
        "      Score = CurrentScore\n",
        "      Kmer = kmer\n",
        "  return Kmer\n",
        "\n",
        "\n",
        "def Score(Motifs, Profile):\n",
        "  Score = 0\n",
        "  k = len(Motifs[0])\n",
        "  for motif in Motifs:\n",
        "    CurrentScore = 1\n",
        "    for i in range(k):\n",
        "      Score *= Profile[motif[i]][i]\n",
        "    Score += CurrentScore\n",
        "  return Score\n",
        "\n",
        "\n",
        "def ProfileFormation(Motifs, k):\n",
        "  Profile = [[1 for i in range(k)] for j in range(4)]\n",
        "  for i in range(k):\n",
        "    for motif in Motifs:\n",
        "      Profile[motif[i]][i] += 1\n",
        "  Profile = numpy.array(Profile)/(len(Motifs)+4)\n",
        "  return Profile\n",
        "\n",
        "\n",
        "def GreedyMotifSearch(Dna, k, t):\n",
        "  BestMotifs = []\n",
        "  for initialmotifs in Dna:\n",
        "    BestMotifs.append(initialmotifs[:k])\n",
        "  w = len(Dna[0])\n",
        "  for x in range(w-k+1):\n",
        "    Motifs = []\n",
        "    Motifs.append(Dna[0][x:x+k])\n",
        "    for y in range(1, t):\n",
        "      Profile = ProfileFormation(Motifs, k)\n",
        "      Motifs.append(MostProbableKmer(Dna[y], k, Profile))\n",
        "    if Score(Motifs, ProfileFormation(Motifs, k)) > Score(Motifs, ProfileFormation(BestMotifs, k)):\n",
        "      BestMotifs = Motifs\n",
        "  return BestMotifs\n",
        "\n",
        "\n",
        "def RandomizedMotifSearch(Dna, k, t):\n",
        "  w = len(Dna[0])\n",
        "  # from Symbol to Number representation\n",
        "  NumDna = [[SymbolToNumber(Symbol) for Symbol in list(line)] for line in Dna]\n",
        "  Motifs = []\n",
        "  for i in range(t):\n",
        "    j = random.randrange(w-k+1)\n",
        "    Motifs.append(NumDna[i][j:j+k])\n",
        "  BestMotifs = Motifs\n",
        "  for x in range(1000):\n",
        "    while True:\n",
        "      Profile = ProfileFormation(Motifs, k)\n",
        "      NewMotifs = []\n",
        "      for Text in NumDna:\n",
        "        NewMotifs.append(MostProbableKmer(Text, k, Profile))\n",
        "      Motifs = NewMotifs\n",
        "      if Score(Motifs, Profile) > Score(BestMotifs, Profile):\n",
        "        BestMotifs = Motifs\n",
        "      else:\n",
        "        break\n",
        "    Motifs = []\n",
        "    for i in range(t):\n",
        "      j = random.randrange(w-k+1)\n",
        "      Motifs.append(NumDna[i][j:j+k])\n",
        "  # from Number to Symbol representation\n",
        "  return [''.join([NumberToSymbol(Number) for Number in line]) for line in BestMotifs]\n",
        "\n",
        "\n",
        "def GibbsSampler(Dna, k, t, N):\n",
        "  w = len(Dna[0])\n",
        "  # from Symbol to Number representation\n",
        "  NumDna = [[SymbolToNumber(Symbol) for Symbol in list(line)] for line in Dna]\n",
        "  Motifs = []\n",
        "  for i in range(t):\n",
        "    j = random.randrange(w-k+1)\n",
        "    Motifs.append(NumDna[i][j:j+k])\n",
        "  BestMotifs = Motifs\n",
        "  for j in range(N):\n",
        "    i = random.randrange(t)\n",
        "    Motifs.pop(i)\n",
        "    Profile = ProfileFormation(Motifs, k)\n",
        "    #Profile-randomly generated k-mer in a string Text.\n",
        "    Motifs.insert(i, MostProbableKmer(NumDna[i], k, Profile))\n",
        "    if Score(Motifs, Profile) > Score(BestMotifs, Profile):\n",
        "      BestMotifs = Motifs\n",
        "  return [''.join([NumberToSymbol(Number) for Number in line]) for line in BestMotifs]\n",
        "\n",
        "\n",
        "def Composition(Text, k):\n",
        "#Generate the k-mer composition of a string.\n",
        "#k-mer composition is the collection of all k-mer substrings of Text (including repeated k-mers).\n",
        "  Kmer = []\n",
        "  for i in range(len(Text)-k+1):\n",
        "    Kmer.append(Text[i:i+k])\n",
        "  Kmer.sort()\n",
        "  #lexicographic order\n",
        "  return Kmer\n",
        "\n",
        "\n",
        "def Reconstruct(Patterns):\n",
        "#Find the string spelled by a genome path.\n",
        "  Text = Patterns[0]\n",
        "  for i in range(1,len(Patterns)):\n",
        "    Text += Patterns[i][-1]\n",
        "  return Text\n",
        "\n",
        "\n",
        "def Overlap(Patterns):\n",
        "#Construct the overlap graph of a collection of k-mers.\n",
        "#Overlap graph has a node for each k-mer in Patterns and connect k-mers Pattern and Pattern' by a directed edge if Suffix(Pattern) is equal to Prefix(Pattern')\n",
        "  Kmers = [Patterns.pop()]\n",
        "  EndOfDna = False\n",
        "  while not EndOfDna:\n",
        "    EndOfDna = True\n",
        "    for kmer in Patterns:\n",
        "      if Kmers[-1][1:] == kmer[:-1]:\n",
        "        Kmers.append(kmer)\n",
        "        Patterns.remove(kmer)\n",
        "        EndOfDna = False\n",
        "  EndOfDna = False\n",
        "  while not EndOfDna:\n",
        "    EndOfDna = True\n",
        "    for kmer in Patterns:\n",
        "      if Kmers[0][:-1] == kmer[1:]:\n",
        "        Kmers.insert(0, kmer)\n",
        "        Patterns.remove(kmer)\n",
        "        EndOfDna = False\n",
        "  AdjList = []\n",
        "  for i in range(len(Kmers)-1):\n",
        "    AdjList.append([Kmers[i], Kmers[i+1]])\n",
        "  AdjList.sort(key = lambda x: x[0])\n",
        "  return AdjList\n",
        "\n",
        "#The de Bruijn graph DeBruijnk(Text) is formed by gluing identically labeled nodes in PathGraphk(Text).\n",
        "def DeBrujinText(Text, k):\n",
        "#Construct the de Bruijn graph of a string.\n",
        "  AdjList = []\n",
        "  for i in range(len(Text)-k+1):\n",
        "    AdjList.append([Text[i:i+k-1], Text[i+1:i+k]])\n",
        "  AdjList.sort(key = lambda x: x[0])\n",
        "  PathGraph = [AdjList.pop(0)]\n",
        "  while AdjList:\n",
        "    ToBeAppended = AdjList.pop(0)\n",
        "    if ToBeAppended[0] == PathGraph[-1][0]:\n",
        "      PathGraph[-1].append(ToBeAppended[1])\n",
        "    else:\n",
        "      PathGraph.append(ToBeAppended)\n",
        "  return PathGraph\n",
        "\n",
        "\n",
        "def DeBrujinPatterns(Patterns, k):\n",
        "#Construct the de Bruijn graph from a collection of k-mers.\n",
        "  AdjList = []\n",
        "  for Kmer in Patterns:\n",
        "    AdjList.append([Kmer[:-1], Kmer[1:]])\n",
        "  AdjList.sort(key = lambda x: x[0])\n",
        "  PathGraph = [AdjList.pop(0)]\n",
        "  while AdjList:\n",
        "    ToBeAppended = AdjList.pop(0)\n",
        "    if ToBeAppended[0] == PathGraph[-1][0]:\n",
        "      PathGraph[-1].append(ToBeAppended[1])\n",
        "    else:\n",
        "      PathGraph.append(ToBeAppended)\n",
        "  return PathGraph\n",
        "\n",
        "\n",
        "def DeBrujinPaired(PairedComposition, k):\n",
        "  AdjList = []\n",
        "  for Kmer in PairedComposition:\n",
        "    AdjList.append([[Kmer[0][:-1], Kmer[1][:-1]],[Kmer[0][1:], Kmer[1][1:]]])\n",
        "  AdjList.sort(key = lambda x: x[0])\n",
        "  PathGraph = [AdjList.pop(0)]\n",
        "  while AdjList:\n",
        "    ToBeAppended = AdjList.pop(0)\n",
        "    if ToBeAppended[0] == PathGraph[-1][0]:\n",
        "      PathGraph[-1].append(ToBeAppended[1])\n",
        "    else:\n",
        "      PathGraph.append(ToBeAppended)\n",
        "  return PathGraph\n",
        "\n",
        "\n",
        "def EulerianPath(PathGraph):\n",
        "  Graph = []\n",
        "  AdjDict = {}\n",
        "  DegreeDict = {}\n",
        "  for Nodes in PathGraph:\n",
        "    for Node in Nodes:\n",
        "      AdjDict.setdefault(Node)\n",
        "      DegreeDict.setdefault(Node, 0)\n",
        "  for Nodes in PathGraph:\n",
        "    AdjDict[Nodes[0]] = Nodes[1:]\n",
        "    DegreeDict[Nodes[0]] = len(Nodes[1:])\n",
        "\n",
        "  for EndNodes in AdjDict.values():\n",
        "    if EndNodes:\n",
        "      for EndNode in EndNodes:\n",
        "        DegreeDict[EndNode] = (DegreeDict[EndNode]-1)\n",
        "\n",
        "  def DFS(index):\n",
        "    while(AdjDict[index]):\n",
        "      DFS(AdjDict[index].pop())\n",
        "    Graph.insert(0, index)\n",
        "\n",
        "  for index in DegreeDict.keys():\n",
        "    if DegreeDict[index]==1: # Choosing a start point\n",
        "      DFS(index)\n",
        "      break\n",
        "\n",
        "  return Graph\n",
        "\n",
        "\n",
        "def DecimalToBinary(Number, k):\n",
        "  if k == 1:\n",
        "    return str(Number)\n",
        "  prefix = Number // 2\n",
        "  r = Number % 2\n",
        "  return DecimalToBinary(prefix, k-1) + str(r)\n",
        "\n",
        "\n",
        "def KUnivercialCircularRing(k):\n",
        "#A k-universal circular string is a circular string that contains every possible k-mer constructed over a given alphabet.\n",
        "  AdjDict = {}\n",
        "  Graph = []\n",
        "  for i in range(2**(k-1)):\n",
        "    Binary = DecimalToBinary(i, k-1)\n",
        "    AdjDict.setdefault(Binary, [Binary[1:]+'1',Binary[1:]+'0'])\n",
        "  def DFS(index):\n",
        "    while(AdjDict[index]):\n",
        "      DFS(AdjDict[index].pop())\n",
        "    Graph.insert(0, index)\n",
        "  DFS('0'*(k-1))\n",
        "  return Graph[:-(k-1)]\n",
        "\n",
        "\n",
        "def StringReconsturctionFromReadPairs(PathGraph, k, d):\n",
        "#Reconstruct a string from its paired composition.\n",
        "#(k,d)-mer is a pair of k-mers in Text separated by distance d.\n",
        "  AdjDict = {}\n",
        "  DegreeDict = {}\n",
        "  PairedGraph = []\n",
        "\n",
        "  for Pair in PathGraph:\n",
        "    for Node in Pair:\n",
        "      AdjDict.setdefault(tuple(Node))\n",
        "      DegreeDict.setdefault(tuple(Node),0)\n",
        "\n",
        "  for Pair in PathGraph:\n",
        "    Prefix = tuple(Pair[0])\n",
        "    Suffix = Pair[1:]\n",
        "    AdjDict[Prefix] = Suffix\n",
        "    DegreeDict[Prefix] = len(Suffix)\n",
        "  for EndNodes in AdjDict.values():\n",
        "    if EndNodes:\n",
        "      for EndNode in EndNodes:\n",
        "        DegreeDict[tuple(EndNode)] = (DegreeDict[tuple(EndNode)]-1)\n",
        "\n",
        "  def DFS(index):\n",
        "    while(AdjDict[index]):\n",
        "      DFS(tuple(AdjDict[index].pop()))\n",
        "    PairedGraph.insert(0, list(index))\n",
        "\n",
        "  for index in DegreeDict.keys():\n",
        "    if DegreeDict[index]==1:\n",
        "      DFS(index)\n",
        "      break\n",
        "\n",
        "  Graph = []\n",
        "  for Pair in PairedGraph:\n",
        "    Graph.append(Pair[0])\n",
        "  for i in range(-k-d,0):\n",
        "    Graph.append(PairedGraph[i][1])\n",
        "  return Graph\n",
        "\n",
        "\n",
        "def ContigGeneration(PathGraph):\n",
        "#Generate the contigs from a collection of reads (with imperfect coverage).\n",
        "#Non-branching if in(v) = out(v) = 1 for each intermediate node v of this path,\n",
        "  Graph = []\n",
        "  AdjDict = {}\n",
        "  DegreeDict = {} # Degree : # of nodes [In, Out]\n",
        "  for Nodes in PathGraph:\n",
        "    for Node in Nodes:\n",
        "      AdjDict.setdefault(Node)\n",
        "      DegreeDict.setdefault(Node, [0,0])\n",
        "  for Nodes in PathGraph:\n",
        "    AdjDict[Nodes[0]] = Nodes[1:]\n",
        "    DegreeDict[Nodes[0]][1] = len(Nodes[1:])\n",
        "\n",
        "  for EndNodes in AdjDict.values():\n",
        "    if EndNodes:\n",
        "      for EndNode in EndNodes:\n",
        "        DegreeDict[EndNode][0] = (DegreeDict[EndNode][0]+1)\n",
        "\n",
        "  def Search(key, contig):\n",
        "    value = AdjDict[key].pop()\n",
        "    contig.append(value)\n",
        "    if DegreeDict[value] == [1,1] and AdjDict[value]:\n",
        "      return Search(value, contig)\n",
        "    else: # Finish Search if value is a branch point or has no out\n",
        "      return Reconstruct(contig)\n",
        "  \n",
        "  Contigs = []\n",
        "  IsNotEmpty = True\n",
        "  while IsNotEmpty:\n",
        "    IsNotEmpty = False\n",
        "    for key in AdjDict.keys():\n",
        "      if AdjDict[key] and not DegreeDict[key] == [1,1]:\n",
        "      # key is a branch point\n",
        "        Contigs.append(Search(key, [key]))\n",
        "        IsNotEmpty = True\n",
        "\n",
        "  return Contigs\n",
        "\n",
        "\n",
        "def ProteinTranslation(Pattern):\n",
        "  Protein = []\n",
        "  for i in range(len(Pattern)//3):\n",
        "    Codon = Pattern[3*i:3*i+3]\n",
        "    if Codon in ['UAA','UAG','UGA']:\n",
        "      break\n",
        "    Protein.append(GeneticCode[Codon])\n",
        "  return ''.join(Protein)\n",
        "\n",
        "\n",
        "def DnaToRna(Dna):\n",
        "  return re.sub('T','U',Dna)\n",
        "\n",
        "\n",
        "def PeptideEncoding(Text, Peptide):\n",
        "#Find substrings of a genome encoding a given amino acid sequence.\n",
        "  Substrings = []\n",
        "  PeptideLen = len(Peptide)\n",
        "  for i in range(len(Text)-3*PeptideLen+1):\n",
        "    substring = Text[i:i+3*PeptideLen]\n",
        "    if ProteinTranslation(DnaToRna(substring)) == Peptide or ProteinTranslation(DnaToRna(ReverseCompliment(substring))) == Peptide:\n",
        "      Substrings.append(substring)\n",
        "  return Substrings\n",
        "\n",
        "\n",
        "def Cyclospectrum(Peptide):\n",
        "#Generate the theoretical spectrum of a cyclic peptide.\n",
        "#The theoretical spectrum of a cyclic peptide Peptide is the collection of all of the masses of its subpeptides\n",
        "  PeptideLen = len(Peptide)\n",
        "  TheoreticalSpectrum = [0,Mass(Peptide)]\n",
        "\n",
        "  Peptide += Peptide\n",
        "  for i in range(1,PeptideLen):\n",
        "    for j in range(PeptideLen):\n",
        "      TheoreticalSpectrum.append(Mass(Peptide[j:j+i]))\n",
        "  \n",
        "  return sorted(TheoreticalSpectrum)\n",
        "\n",
        "\n",
        "def Mass(Peptide):\n",
        "  Mass = 0\n",
        "  for AminoAcid in Peptide:\n",
        "    Mass += IntegerMass[AminoAcid]\n",
        "  return Mass\n",
        "\n",
        "\n",
        "def BFCyclopeptideSequencing(Mass):\n",
        "#Compute the number of peptides of given total mass.\n",
        "  if Mass in ReducedMass.values():\n",
        "    global cnt\n",
        "    cnt += 1\n",
        "  elif Mass > 57:\n",
        "    for AminoAcid in ReducedMass.values():\n",
        "      if Mass > AminoAcid:\n",
        "        BFCyclopeptideSequencing(Mass-AminoAcid)\n",
        "\n",
        "\n",
        "def CyclopeptideSequencing(Spectrum):\n",
        "  \n",
        "  def Expand(CandidatePeptides):\n",
        "    Expand = []\n",
        "    for Peptide in CandidatePeptides:\n",
        "      for AminoAcid in ReducedMass.keys():\n",
        "        Expand.append(Peptide+AminoAcid)\n",
        "    return Expand\n",
        "  CandidatePeptides = list(ReducedMass.keys())\n",
        "  FinalPeptides = []\n",
        "  while True:\n",
        "    CopyCandidatePeptides = CandidatePeptides.copy()\n",
        "    for Peptide in CopyCandidatePeptides:\n",
        "      Peptidespectrum = Cyclospectrum(Peptide)\n",
        "      if Peptidespectrum == Spectrum:\n",
        "        FinalPeptides.append(Peptide)\n",
        "        CandidatePeptides.remove(Peptide)\n",
        "      else:\n",
        "        for Fragment in Peptidespectrum:\n",
        "          if Fragment not in Spectrum:\n",
        "            CandidatePeptides.remove(Peptide)\n",
        "            break\n",
        "    if not CandidatePeptides:\n",
        "      break\n",
        "    print(CandidatePeptides)\n",
        "    CandidatePeptides = Expand(CandidatePeptides)\n",
        "  print(FinalPeptides)\n",
        "  return FinalPeptides\n",
        "\n",
        "\n",
        "GeneticCode = {'AAA':'K','AAC':'N','AAG':'K','AAU':'N','ACA':'T','ACC':'T','ACG':'T','ACU':'T',\n",
        "               'AGA':'R','AGC':'S','AGG':'R','AGU':'S','AUA':'I','AUC':'I','AUG':'M','AUU':'I',\n",
        "               'CAA':'Q','CAC':'H','CAG':'Q','CAU':'H','CCA':'P','CCC':'P','CCG':'P','CCU':'P',\n",
        "               'CGA':'R','CGC':'R','CGG':'R','CGU':'R','CUA':'L','CUC':'L','CUG':'L','CUU':'L',\n",
        "               'GAA':'E','GAC':'D','GAG':'E','GAU':'D','GCA':'A','GCC':'A','GCG':'A','GCU':'A',\n",
        "               'GGA':'G','GGC':'G','GGG':'G','GGU':'G','GUA':'V','GUC':'V','GUG':'V','GUU':'V',\n",
        "               'UAA':'*','UAC':'Y','UAG':'*','UAU':'Y','UCA':'S','UCC':'S','UCG':'S','UCU':'S',\n",
        "               'UGA':'*','UGC':'C','UGG':'W','UGU':'C','UUA':'L','UUC':'F','UUG':'L','UUU':'F'}\n",
        "\n",
        "IntegerMass = {'G':57,'A':71,'S':87,'P':97,'V':99,'T':101,'C':103,'I':113,'L':113,'N':114,\n",
        "               'D':115,'K':128,'Q':128,'E':129,'M':131,'H':137,'F':147,'R':156,'Y':163,'W':186}\n",
        "\n",
        "ReducedMass = {'G':57,'A':71,'S':87,'P':97,'V':99,'T':101,'C':103,'I':113,'N':114,\n",
        "               'D':115,'K':128,'E':129,'M':131,'H':137,'F':147,'R':156,'Y':163,'W':186}\n",
        "\n",
        "f = open('/content/drive/My Drive/Colab Notebooks/input.txt', 'r')\n",
        "Spectrum = list(map(int,f.readline().split(' ')))\n",
        "print(CyclopeptideSequencing(Spectrum))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'P', 'V', 'C', 'I', 'N', 'D', 'M', 'H']\n",
            "['AM', 'AH', 'PV', 'PC', 'PM', 'VP', 'VC', 'VD', 'CP', 'CV', 'CH', 'II', 'IN', 'ID', 'NI', 'NN', 'NM', 'DV', 'DI', 'MA', 'MP', 'MN', 'HA', 'HC']\n",
            "['PVC', 'PCV', 'VPC', 'VCP', 'CPV', 'CVP', 'III', 'IIN', 'IID', 'INI', 'INN', 'IDI', 'NII', 'NIN', 'NNI', 'DII']\n",
            "['IIIN', 'IINI', 'INII', 'NIII']\n",
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPTIdW_DcOQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41550c5d-3be2-447f-e7df-e52879ab9e23"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}