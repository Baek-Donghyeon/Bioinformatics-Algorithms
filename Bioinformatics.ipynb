{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bioinformatics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1spa6WIJ7AnqFEx23npocnCrRULcEQRwb",
      "authorship_tag": "ABX9TyPYku/nleDWfirb1cpBA2Jo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baek-Donghyeon/Bioinformatics-Algorithms/blob/main/Bioinformatics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0vB1kWjeVkM"
      },
      "source": [
        "# Bioinformatics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKZGqBuzeXD3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "d1b57c0e-dbfc-4cd7-99d9-4d908efe63df"
      },
      "source": [
        "import numpy\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "from itertools import combinations\n",
        "from functools import reduce\n",
        "import copy\n",
        "sys.setrecursionlimit(3000)\n",
        "\n",
        "def k_mer_of(text, k):\n",
        "  for i in range(len(text) - k + 1):\n",
        "    yield text[i:i+k]\n",
        "\n",
        "def hamming_distance(pattern, text):\n",
        "  # Minimum distance between pattern and all k_mers in text\n",
        "  k = len(pattern)\n",
        "  distance = k\n",
        "  for k_mer in k_mer_of(text, k):\n",
        "    distance = min(distance, sum(pattern[j] != k_mer[j] for j in range(k)))\n",
        "  return distance\n",
        "\n",
        "def pattern_to_number(pattern):\n",
        "  symbol_to_number = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "  if len(Pattern) == 0:\n",
        "      return 0\n",
        "  return 4*pattern_to_number(pattern[:-1]) + symbol_to_number[pattern[-1]]\n",
        "\n",
        "def number_to_pattern(number, k):\n",
        "  number_to_symbol = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n",
        "  try:\n",
        "    if k == 1:\n",
        "      return number_to_symbol(number)\n",
        "    return number_to_pattern(number // 4, k-1) + number_to_symbol[number % 4]\n",
        "  except:\n",
        "    raise ValueError()\n",
        "\n",
        "def count_pattern(text, pattern):\n",
        "  return sum(k_mer == pattern for k_mer in k_mer_of(text, len(pattern)))\n",
        "\n",
        "def find_frequent_k_mer(text, k, distance = 0, reverse_complement = False):\n",
        "  ''' k   length of the k_mer '''\n",
        "  frequency_dict = dict(frequency_dict(text, k, distance, reverse_complement))\n",
        "  max = max(frequency_dict, key = lambda x : frequency_dict[x])\n",
        "  return list(filter(lambda x : x[1] == max, frequency_dict.items())) \n",
        "\n",
        "def frequency_dict(text, k, distance = 0, reverse_complement = False):\n",
        "  ''' k   length of the k_mer '''\n",
        "  if reverse_complement:\n",
        "    return frequency_dict(reverse_complement(text), k, distance) + frequency_dict(text, k, distance)\n",
        "  else:\n",
        "    return Counter([neighbor for k_mer in k_mer_of(text, k) for neighbor in neighbor(k_mer, distance)])\n",
        "\n",
        "def reverse_complement(text):\n",
        "  compliment_dict = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G'}\n",
        "  return ''.join(reversed([compliment_dict[base] for base in text]))\n",
        "\n",
        "def find_pattern_occurence(text, pattern, distance = 0):\n",
        "  # hamming_distance(text, pattern) â‰¤ d\n",
        "  k = len(pattern)\n",
        "  return [i for i in range(len(text) - k + 1) if hamming_distance(text[i:i+k], pattern) <= distance]\n",
        "\n",
        "def find_clump(text, k, L, t):\n",
        "  '''\n",
        "  k   length of the k_mer\n",
        "  L   length of an interval\n",
        "  t   min ocurrences of a pattern in the interval\n",
        "  '''\n",
        "  answer = []\n",
        "  position_dict = defaultdict(list)\n",
        "  frequency_dict = frequency_dict(text, k)\n",
        "  for pattern, frequency in frequency_dict.items():\n",
        "    if frequency >= t:\n",
        "      position_dict[pattern] = find_occurrences_of_pattern(text, pattern)\n",
        "  for pattern, position in position_dict.items():\n",
        "    for i in range(len(position) - t + 1):\n",
        "      if position[i+t-1] - position[i] <= L - k + 1:\n",
        "        answer.append(pattern)\n",
        "  return answer\n",
        "\n",
        "def find_min_skew_position(text):\n",
        "  # skew : abs(#'G'-#'C')\n",
        "  skew = [0]\n",
        "  for base in text:\n",
        "    if base == 'C':\n",
        "      skew.append(skew[-1]-1)\n",
        "    elif base == 'G':\n",
        "      skew.append(skew[-1]+1)\n",
        "    else:\n",
        "      skew.append(skew[-1])\n",
        "  min = min(skew)\n",
        "  return list(filter(lambda x : x == min, skew)) # return minimum skew\n",
        "\n",
        "def neighbor(pattern, distance):\n",
        "  length = len(pattern)\n",
        "  mismatch_base = [number_to_pattern(number, k) for number in range(4**distance)]\n",
        "  for positions in combinations(iter(range(length)), distance):\n",
        "    for base in mismatch_base:\n",
        "      neighbor = copy.deepcopy(pattern)\n",
        "      for i in distance:\n",
        "        neighbor[position[i]] = base[i]\n",
        "        yield neighbor\n",
        "      \n",
        "\n",
        "def enumerate_motif(strings, k, distance):\n",
        "  # Find all (k, distance)-motifs in a collection of strings.\n",
        "  neighbor_list = []\n",
        "  for text in strings:\n",
        "    neighbor_list.append(set(neighbor(text, k, distance)))\n",
        "  motifs = neighbor_list[0]\n",
        "  for neighbor in neighbor_list:\n",
        "    motifs = motifs & neighbor\n",
        "  return list(motifs)\n",
        "\n",
        "\n",
        "def find_median_string(strings, k, distance = 0):\n",
        "  # A median string for Dna minimizes d(Pattern, Dna) over all k-mers Pattern.\n",
        "  motifs = enumerate_motif(strings, k, distance)\n",
        "  if not motifs:\n",
        "    find_median_string(strings, k, distance + 1)\n",
        "  else:\n",
        "    motifs_dict = defaultdict(int)\n",
        "    for pattern in motifs:\n",
        "      motifs_dict[pattern] = sum(hamming_distance(pattern, text) for text in strings)\n",
        "    return min(motifs_dict, key = lambda x : motifs_dict[x]) # return key that minimizes the value\n",
        "\n",
        "\n",
        "def find_profile_probable_k_mer(text, k, profile):\n",
        "  # A k-mer that was most likely to have been generated by Profile among all k-mers in Text.\n",
        "  probability = 0\n",
        "  kmer = ''\n",
        "  for i in range(len(Text)-k):\n",
        "    CurrentScore = 1\n",
        "    kmer = Text[i:i+k]\n",
        "    for j in range(k):\n",
        "      CurrentScore *= Profile[kmer[j]][j]\n",
        "    if CurrentScore > Score:\n",
        "      Score = CurrentScore\n",
        "      Kmer = kmer\n",
        "  return Kmer\n",
        "\n",
        "\n",
        "def score(motif, profile):\n",
        "  return sum(reduce(lambda x, y: x*y, list(profile[pattern_to_number(k_mer[i])][i]\n",
        "              for i in range(k))) for k_mer in motif)\n",
        "\n",
        "def form_profile(motif):\n",
        "  k = len(motif[0])\n",
        "  profile = numpy.full((4,k), 1) # pseudocount\n",
        "  for i in range(k):\n",
        "    for k_mer in motif:\n",
        "      Profile[pattern_to_number(k_mer[i])][i] += 1\n",
        "  return profile/(len(motif)+4)\n",
        "\n",
        "\n",
        "def greedy_motif_search(strings, k):\n",
        "  best_motif = [text[:k] for text in strings]\n",
        "  for i in range(len(strings[0]) - k + 1):\n",
        "    motif = [strings[0][i:i+k]]\n",
        "    for j in range(1,len(strings)):\n",
        "      profile = form_profile(motif)\n",
        "      motif.append(find_profile_probable_k_mer(strings[j], k, motif))\n",
        "    if score(motif) < score(best_motif):\n",
        "      best_motif = motif\n",
        "  return best_motif\n",
        "\n",
        "\n",
        "def RandomizedMotifSearch(Dna, k, t):\n",
        "  w = len(Dna[0])\n",
        "  # from Symbol to Number representation\n",
        "  NumDna = [[SymbolToNumber(Symbol) for Symbol in list(line)] for line in Dna]\n",
        "  Motifs = []\n",
        "  for i in range(t):\n",
        "    j = random.randrange(w-k+1)\n",
        "    Motifs.append(NumDna[i][j:j+k])\n",
        "  BestMotifs = Motifs\n",
        "  for x in range(1000):\n",
        "    while True:\n",
        "      Profile = ProfileFormation(Motifs, k)\n",
        "      NewMotifs = []\n",
        "      for Text in NumDna:\n",
        "        NewMotifs.append(MostProbableKmer(Text, k, Profile))\n",
        "      Motifs = NewMotifs\n",
        "      if Score(Motifs, Profile) > Score(BestMotifs, Profile):\n",
        "        BestMotifs = Motifs\n",
        "      else:\n",
        "        break\n",
        "    Motifs = []\n",
        "    for i in range(t):\n",
        "      j = random.randrange(w-k+1)\n",
        "      Motifs.append(NumDna[i][j:j+k])\n",
        "  # from Number to Symbol representation\n",
        "  return [''.join([NumberToSymbol(Number) for Number in line]) for line in BestMotifs]\n",
        "\n",
        "\n",
        "def GibbsSampler(Dna, k, t, N):\n",
        "  w = len(Dna[0])\n",
        "  # from Symbol to Number representation\n",
        "  NumDna = [[SymbolToNumber(Symbol) for Symbol in list(line)] for line in Dna]\n",
        "  Motifs = []\n",
        "  for i in range(t):\n",
        "    j = random.randrange(w-k+1)\n",
        "    Motifs.append(NumDna[i][j:j+k])\n",
        "  BestMotifs = Motifs\n",
        "  for j in range(N):\n",
        "    i = random.randrange(t)\n",
        "    Motifs.pop(i)\n",
        "    Profile = ProfileFormation(Motifs, k)\n",
        "    #Profile-randomly generated k-mer in a string Text.\n",
        "    Motifs.insert(i, MostProbableKmer(NumDna[i], k, Profile))\n",
        "    if Score(Motifs, Profile) > Score(BestMotifs, Profile):\n",
        "      BestMotifs = Motifs\n",
        "  return [''.join([NumberToSymbol(Number) for Number in line]) for line in BestMotifs]\n",
        "\n",
        "\n",
        "def Composition(Text, k):\n",
        "#Generate the k-mer composition of a string.\n",
        "#k-mer composition is the collection of all k-mer substrings of Text (including repeated k-mers).\n",
        "  Kmer = []\n",
        "  for i in range(len(Text)-k+1):\n",
        "    Kmer.append(Text[i:i+k])\n",
        "  Kmer.sort()\n",
        "  #lexicographic order\n",
        "  return Kmer\n",
        "\n",
        "\n",
        "def Reconstruct(Patterns):\n",
        "#Find the string spelled by a genome path.\n",
        "  Text = Patterns[0]\n",
        "  for i in range(1,len(Patterns)):\n",
        "    Text += Patterns[i][-1]\n",
        "  return Text\n",
        "\n",
        "\n",
        "def Overlap(Patterns):\n",
        "#Construct the overlap graph of a collection of k-mers.\n",
        "#Overlap graph has a node for each k-mer in Patterns and connect k-mers Pattern and Pattern' by a directed edge if Suffix(Pattern) is equal to Prefix(Pattern')\n",
        "  Kmers = [Patterns.pop()]\n",
        "  EndOfDna = False\n",
        "  while not EndOfDna:\n",
        "    EndOfDna = True\n",
        "    for kmer in Patterns:\n",
        "      if Kmers[-1][1:] == kmer[:-1]:\n",
        "        Kmers.append(kmer)\n",
        "        Patterns.remove(kmer)\n",
        "        EndOfDna = False\n",
        "  EndOfDna = False\n",
        "  while not EndOfDna:\n",
        "    EndOfDna = True\n",
        "    for kmer in Patterns:\n",
        "      if Kmers[0][:-1] == kmer[1:]:\n",
        "        Kmers.insert(0, kmer)\n",
        "        Patterns.remove(kmer)\n",
        "        EndOfDna = False\n",
        "  AdjList = []\n",
        "  for i in range(len(Kmers)-1):\n",
        "    AdjList.append([Kmers[i], Kmers[i+1]])\n",
        "  AdjList.sort(key = lambda x: x[0])\n",
        "  return AdjList\n",
        "\n",
        "#The de Bruijn graph DeBruijnk(Text) is formed by gluing identically labeled nodes in PathGraphk(Text).\n",
        "def DeBrujinText(Text, k):\n",
        "#Construct the de Bruijn graph of a string.\n",
        "  AdjList = []\n",
        "  for i in range(len(Text)-k+1):\n",
        "    AdjList.append([Text[i:i+k-1], Text[i+1:i+k]])\n",
        "  AdjList.sort(key = lambda x: x[0])\n",
        "  PathGraph = [AdjList.pop(0)]\n",
        "  while AdjList:\n",
        "    ToBeAppended = AdjList.pop(0)\n",
        "    if ToBeAppended[0] == PathGraph[-1][0]:\n",
        "      PathGraph[-1].append(ToBeAppended[1])\n",
        "    else:\n",
        "      PathGraph.append(ToBeAppended)\n",
        "  return PathGraph\n",
        "\n",
        "\n",
        "def DeBrujinPatterns(Patterns, k):\n",
        "#Construct the de Bruijn graph from a collection of k-mers.\n",
        "  AdjList = []\n",
        "  for Kmer in Patterns:\n",
        "    AdjList.append([Kmer[:-1], Kmer[1:]])\n",
        "  AdjList.sort(key = lambda x: x[0])\n",
        "  PathGraph = [AdjList.pop(0)]\n",
        "  while AdjList:\n",
        "    ToBeAppended = AdjList.pop(0)\n",
        "    if ToBeAppended[0] == PathGraph[-1][0]:\n",
        "      PathGraph[-1].append(ToBeAppended[1])\n",
        "    else:\n",
        "      PathGraph.append(ToBeAppended)\n",
        "  return PathGraph\n",
        "\n",
        "\n",
        "def DeBrujinPaired(PairedComposition, k):\n",
        "  AdjList = []\n",
        "  for Kmer in PairedComposition:\n",
        "    AdjList.append([[Kmer[0][:-1], Kmer[1][:-1]],[Kmer[0][1:], Kmer[1][1:]]])\n",
        "  AdjList.sort(key = lambda x: x[0])\n",
        "  PathGraph = [AdjList.pop(0)]\n",
        "  while AdjList:\n",
        "    ToBeAppended = AdjList.pop(0)\n",
        "    if ToBeAppended[0] == PathGraph[-1][0]:\n",
        "      PathGraph[-1].append(ToBeAppended[1])\n",
        "    else:\n",
        "      PathGraph.append(ToBeAppended)\n",
        "  return PathGraph\n",
        "\n",
        "\n",
        "def EulerianPath(PathGraph):\n",
        "  Graph = []\n",
        "  AdjDict = {}\n",
        "  DegreeDict = {}\n",
        "  for Nodes in PathGraph:\n",
        "    for Node in Nodes:\n",
        "      AdjDict.setdefault(Node)\n",
        "      DegreeDict.setdefault(Node, 0)\n",
        "  for Nodes in PathGraph:\n",
        "    AdjDict[Nodes[0]] = Nodes[1:]\n",
        "    DegreeDict[Nodes[0]] = len(Nodes[1:])\n",
        "\n",
        "  for EndNodes in AdjDict.values():\n",
        "    if EndNodes:\n",
        "      for EndNode in EndNodes:\n",
        "        DegreeDict[EndNode] = (DegreeDict[EndNode]-1)\n",
        "\n",
        "  def DFS(index):\n",
        "    while(AdjDict[index]):\n",
        "      DFS(AdjDict[index].pop())\n",
        "    Graph.insert(0, index)\n",
        "\n",
        "  for index in DegreeDict.keys():\n",
        "    if DegreeDict[index]==1: # Choosing a start point\n",
        "      DFS(index)\n",
        "      break\n",
        "\n",
        "  return Graph\n",
        "\n",
        "\n",
        "def DecimalToBinary(Number, k):\n",
        "  if k == 1:\n",
        "    return str(Number)\n",
        "  prefix = Number // 2\n",
        "  r = Number % 2\n",
        "  return DecimalToBinary(prefix, k-1) + str(r)\n",
        "\n",
        "\n",
        "def KUnivercialCircularRing(k):\n",
        "#A k-universal circular string is a circular string that contains every possible k-mer constructed over a given alphabet.\n",
        "  AdjDict = {}\n",
        "  Graph = []\n",
        "  for i in range(2**(k-1)):\n",
        "    Binary = DecimalToBinary(i, k-1)\n",
        "    AdjDict.setdefault(Binary, [Binary[1:]+'1',Binary[1:]+'0'])\n",
        "  def DFS(index):\n",
        "    while(AdjDict[index]):\n",
        "      DFS(AdjDict[index].pop())\n",
        "    Graph.insert(0, index)\n",
        "  DFS('0'*(k-1))\n",
        "  return Graph[:-(k-1)]\n",
        "\n",
        "\n",
        "def StringReconsturctionFromReadPairs(PathGraph, k, d):\n",
        "#Reconstruct a string from its paired composition.\n",
        "#(k,d)-mer is a pair of k-mers in Text separated by distance d.\n",
        "  AdjDict = {}\n",
        "  DegreeDict = {}\n",
        "  PairedGraph = []\n",
        "\n",
        "  for Pair in PathGraph:\n",
        "    for Node in Pair:\n",
        "      AdjDict.setdefault(tuple(Node))\n",
        "      DegreeDict.setdefault(tuple(Node),0)\n",
        "\n",
        "  for Pair in PathGraph:\n",
        "    Prefix = tuple(Pair[0])\n",
        "    Suffix = Pair[1:]\n",
        "    AdjDict[Prefix] = Suffix\n",
        "    DegreeDict[Prefix] = len(Suffix)\n",
        "  for EndNodes in AdjDict.values():\n",
        "    if EndNodes:\n",
        "      for EndNode in EndNodes:\n",
        "        DegreeDict[tuple(EndNode)] = (DegreeDict[tuple(EndNode)]-1)\n",
        "\n",
        "  def DFS(index):\n",
        "    while(AdjDict[index]):\n",
        "      DFS(tuple(AdjDict[index].pop()))\n",
        "    PairedGraph.insert(0, list(index))\n",
        "\n",
        "  for index in DegreeDict.keys():\n",
        "    if DegreeDict[index]==1:\n",
        "      DFS(index)\n",
        "      break\n",
        "\n",
        "  Graph = []\n",
        "  for Pair in PairedGraph:\n",
        "    Graph.append(Pair[0])\n",
        "  for i in range(-k-d,0):\n",
        "    Graph.append(PairedGraph[i][1])\n",
        "  return Graph\n",
        "\n",
        "\n",
        "def ContigGeneration(PathGraph):\n",
        "#Generate the contigs from a collection of reads (with imperfect coverage).\n",
        "#Non-branching if in(v) = out(v) = 1 for each intermediate node v of this path,\n",
        "  Graph = []\n",
        "  AdjDict = {}\n",
        "  DegreeDict = {} # Degree : # of nodes [In, Out]\n",
        "  for Nodes in PathGraph:\n",
        "    for Node in Nodes:\n",
        "      AdjDict.setdefault(Node)\n",
        "      DegreeDict.setdefault(Node, [0,0])\n",
        "  for Nodes in PathGraph:\n",
        "    AdjDict[Nodes[0]] = Nodes[1:]\n",
        "    DegreeDict[Nodes[0]][1] = len(Nodes[1:])\n",
        "\n",
        "  for EndNodes in AdjDict.values():\n",
        "    if EndNodes:\n",
        "      for EndNode in EndNodes:\n",
        "        DegreeDict[EndNode][0] = (DegreeDict[EndNode][0]+1)\n",
        "\n",
        "  def Search(key, contig):\n",
        "    value = AdjDict[key].pop()\n",
        "    contig.append(value)\n",
        "    if DegreeDict[value] == [1,1] and AdjDict[value]:\n",
        "      return Search(value, contig)\n",
        "    else: # Finish Search if value is a branch point or has no out\n",
        "      return Reconstruct(contig)\n",
        "  \n",
        "  Contigs = []\n",
        "  IsNotEmpty = True\n",
        "  while IsNotEmpty:\n",
        "    IsNotEmpty = False\n",
        "    for key in AdjDict.keys():\n",
        "      if AdjDict[key] and not DegreeDict[key] == [1,1]:\n",
        "      # key is a branch point\n",
        "        Contigs.append(Search(key, [key]))\n",
        "        IsNotEmpty = True\n",
        "\n",
        "  return Contigs\n",
        "\n",
        "\n",
        "def ProteinTranslation(Pattern):\n",
        "  Protein = []\n",
        "  for i in range(len(Pattern)//3):\n",
        "    Codon = Pattern[3*i:3*i+3]\n",
        "    if Codon in ['UAA','UAG','UGA']:\n",
        "      break\n",
        "    Protein.append(GeneticCode[Codon])\n",
        "  return ''.join(Protein)\n",
        "\n",
        "\n",
        "def DnaToRna(Dna):\n",
        "  return re.sub('T','U',Dna)\n",
        "\n",
        "\n",
        "def PeptideEncoding(Text, Peptide):\n",
        "#Find substrings of a genome encoding a given amino acid sequence.\n",
        "  Substrings = []\n",
        "  PeptideLen = len(Peptide)\n",
        "  for i in range(len(Text)-3*PeptideLen+1):\n",
        "    substring = Text[i:i+3*PeptideLen]\n",
        "    if ProteinTranslation(DnaToRna(substring)) == Peptide or ProteinTranslation(DnaToRna(ReverseCompliment(substring))) == Peptide:\n",
        "      Substrings.append(substring)\n",
        "  return Substrings\n",
        "\n",
        "\n",
        "def Cyclospectrum(Peptide):\n",
        "#Generate the theoretical spectrum of a cyclic peptide.\n",
        "#The theoretical spectrum of a cyclic peptide Peptide is the collection of all of the masses of its subpeptides\n",
        "  PeptideLen = len(Peptide)\n",
        "  TheoreticalSpectrum = [0,Mass(Peptide)]\n",
        "\n",
        "  Peptide += Peptide\n",
        "  for i in range(1,PeptideLen):\n",
        "    for j in range(PeptideLen):\n",
        "      TheoreticalSpectrum.append(Mass(Peptide[j:j+i]))\n",
        "  \n",
        "  return sorted(TheoreticalSpectrum)\n",
        "\n",
        "\n",
        "def Mass(Peptide):\n",
        "  Mass = 0\n",
        "  for AminoAcid in Peptide:\n",
        "    Mass += IntegerMass[AminoAcid]\n",
        "  return Mass\n",
        "\n",
        "\n",
        "def BFCyclopeptideSequencing(Mass):\n",
        "#Compute the number of peptides of given total mass.\n",
        "  if Mass in ReducedMass.values():\n",
        "    global cnt\n",
        "    cnt += 1\n",
        "  elif Mass > 57:\n",
        "    for AminoAcid in ReducedMass.values():\n",
        "      if Mass > AminoAcid:\n",
        "        BFCyclopeptideSequencing(Mass-AminoAcid)\n",
        "\n",
        "\n",
        "def CyclopeptideSequencing(Spectrum):\n",
        "  \n",
        "  def Expand(CandidatePeptides):\n",
        "    Expand = []\n",
        "    for Peptide in CandidatePeptides:\n",
        "      for AminoAcid in ReducedMass.keys():\n",
        "        Expand.append(Peptide+AminoAcid)\n",
        "    return Expand\n",
        "  CandidatePeptides = list(ReducedMass.keys())\n",
        "  FinalPeptides = []\n",
        "  while True:\n",
        "    CopyCandidatePeptides = CandidatePeptides.copy()\n",
        "    for Peptide in CopyCandidatePeptides:\n",
        "      Peptidespectrum = Cyclospectrum(Peptide)\n",
        "      if Peptidespectrum == Spectrum:\n",
        "        FinalPeptides.append(Peptide)\n",
        "        CandidatePeptides.remove(Peptide)\n",
        "      else:\n",
        "        for Fragment in Peptidespectrum:\n",
        "          if Fragment not in Spectrum:\n",
        "            CandidatePeptides.remove(Peptide)\n",
        "            break\n",
        "    if not CandidatePeptides:\n",
        "      break\n",
        "    print(CandidatePeptides)\n",
        "    CandidatePeptides = Expand(CandidatePeptides)\n",
        "  print(FinalPeptides)\n",
        "  return FinalPeptides\n",
        "\n",
        "'''\n",
        "GeneticCode = {'AAA':'K','AAC':'N','AAG':'K','AAU':'N','ACA':'T','ACC':'T','ACG':'T','ACU':'T',\n",
        "               'AGA':'R','AGC':'S','AGG':'R','AGU':'S','AUA':'I','AUC':'I','AUG':'M','AUU':'I',\n",
        "               'CAA':'Q','CAC':'H','CAG':'Q','CAU':'H','CCA':'P','CCC':'P','CCG':'P','CCU':'P',\n",
        "               'CGA':'R','CGC':'R','CGG':'R','CGU':'R','CUA':'L','CUC':'L','CUG':'L','CUU':'L',\n",
        "               'GAA':'E','GAC':'D','GAG':'E','GAU':'D','GCA':'A','GCC':'A','GCG':'A','GCU':'A',\n",
        "               'GGA':'G','GGC':'G','GGG':'G','GGU':'G','GUA':'V','GUC':'V','GUG':'V','GUU':'V',\n",
        "               'UAA':'*','UAC':'Y','UAG':'*','UAU':'Y','UCA':'S','UCC':'S','UCG':'S','UCU':'S',\n",
        "               'UGA':'*','UGC':'C','UGG':'W','UGU':'C','UUA':'L','UUC':'F','UUG':'L','UUU':'F'}\n",
        "\n",
        "IntegerMass = {'G':57,'A':71,'S':87,'P':97,'V':99,'T':101,'C':103,'I':113,'L':113,'N':114,\n",
        "               'D':115,'K':128,'Q':128,'E':129,'M':131,'H':137,'F':147,'R':156,'Y':163,'W':186}\n",
        "\n",
        "ReducedMass = {'G':57,'A':71,'S':87,'P':97,'V':99,'T':101,'C':103,'I':113,'N':114,\n",
        "               'D':115,'K':128,'E':129,'M':131,'H':137,'F':147,'R':156,'Y':163,'W':186}\n",
        "\n",
        "f = open('/content/drive/My Drive/Colab Notebooks/input.txt', 'r')\n",
        "Spectrum = list(map(int,f.readline().split(' ')))\n",
        "print(CyclopeptideSequencing(Spectrum))\n",
        "f.close()\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nGeneticCode = {'AAA':'K','AAC':'N','AAG':'K','AAU':'N','ACA':'T','ACC':'T','ACG':'T','ACU':'T',\\n               'AGA':'R','AGC':'S','AGG':'R','AGU':'S','AUA':'I','AUC':'I','AUG':'M','AUU':'I',\\n               'CAA':'Q','CAC':'H','CAG':'Q','CAU':'H','CCA':'P','CCC':'P','CCG':'P','CCU':'P',\\n               'CGA':'R','CGC':'R','CGG':'R','CGU':'R','CUA':'L','CUC':'L','CUG':'L','CUU':'L',\\n               'GAA':'E','GAC':'D','GAG':'E','GAU':'D','GCA':'A','GCC':'A','GCG':'A','GCU':'A',\\n               'GGA':'G','GGC':'G','GGG':'G','GGU':'G','GUA':'V','GUC':'V','GUG':'V','GUU':'V',\\n               'UAA':'*','UAC':'Y','UAG':'*','UAU':'Y','UCA':'S','UCC':'S','UCG':'S','UCU':'S',\\n               'UGA':'*','UGC':'C','UGG':'W','UGU':'C','UUA':'L','UUC':'F','UUG':'L','UUU':'F'}\\n\\nIntegerMass = {'G':57,'A':71,'S':87,'P':97,'V':99,'T':101,'C':103,'I':113,'L':113,'N':114,\\n               'D':115,'K':128,'Q':128,'E':129,'M':131,'H':137,'F':147,'R':156,'Y':163,'W':186}\\n\\nReducedMass = {'G':57,'A':71,'S':87,'P':97,'V':99,'T':101,'C':103,'I':113,'N':114,\\n               'D':115,'K':128,'E':129,'M':131,'H':137,'F':147,'R':156,'Y':163,'W':186}\\n\\nf = open('/content/drive/My Drive/Colab Notebooks/input.txt', 'r')\\nSpectrum = list(map(int,f.readline().split(' ')))\\nprint(CyclopeptideSequencing(Spectrum))\\nf.close()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPTIdW_DcOQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41550c5d-3be2-447f-e7df-e52879ab9e23"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}